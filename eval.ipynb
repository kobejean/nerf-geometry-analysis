{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nga.utils import load_config, plane_eval_ray_bundle, save_as_image, convert_to_transformed_space\n",
    "from nerfstudio.utils.eval_utils import eval_load_checkpoint\n",
    "from nerfstudio.cameras.rays import RayBundle\n",
    "from nerfstudio.utils import colormaps\n",
    "from nerfstudio.utils.io import load_from_json\n",
    "\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import torch\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sphere_eval_ray_bundle(dataparser_transforms_data, near_z, n = 1001):\n",
    "    dataparser_scale = dataparser_transforms_data[\"scale\"]\n",
    "    x = torch.linspace(-0.5, 0.5, n)\n",
    "    y = torch.linspace(-0.5, 0.5, n)\n",
    "    z = near_z\n",
    "    grid_x, grid_y = torch.meshgrid(x, y)\n",
    "    origins = torch.stack([grid_x, grid_y, z * torch.ones([n, n])], dim=-1)\n",
    "    origins = convert_to_transformed_space(origins, dataparser_transforms_data)\n",
    "    directions = torch.zeros_like(origins)\n",
    "    directions[:, :, 2] = -1.0\n",
    "    pixel_area = (dataparser_scale ** 2) * torch.ones((n, n, 1)) / (n ** 2)\n",
    "    nears = torch.zeros((n, n, 1))\n",
    "    fars = torch.ones((n, n, 1)) * 2 * near_z * dataparser_scale\n",
    "    camera_indices = torch.zeros((n, n, 1))\n",
    "\n",
    "    ray_bundle = RayBundle(\n",
    "        origins=origins, directions=directions, pixel_area=pixel_area,\n",
    "        camera_indices=camera_indices,\n",
    "        nears=nears,\n",
    "        # fars=fars, \n",
    "    )\n",
    "    return ray_bundle\n",
    "\n",
    "def load_metadata(config):\n",
    "    if config.data.suffix == \".json\":\n",
    "        meta = load_from_json(config.data)\n",
    "        data_dir = config.data.parent\n",
    "    else:\n",
    "        meta = load_from_json(config.data / \"transforms.json\")\n",
    "        data_dir = config.data\n",
    "    return meta, data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config_path = \"outputs/pattern_plane1_720x480/tensorf/2023-09-01_085608/config.yml\"\n",
    "# config_path = \"outputs/pattern_plane1_720x480/instant-ngp/2023-08-31_194733/config.yml\"\n",
    "# config_path = \"outputs/pattern_plane1_720x480/nerfacto/2023-09-01_092209/config.yml\"\n",
    "# config_path = \"outputs/pattern_plane1_720x480/nerfacto/2023-09-01_102747/config.yml\"\n",
    "# config_path = \"outputs/pattern_plane1_720x480/nerfacto/2023-09-14_142127/config.yml\"\n",
    "config_path = \"outputs/checkered_square_pyramid/nerfacto/2023-09-15_152357/config.yml\"\n",
    "\n",
    "\n",
    "config = load_config(config_path)\n",
    "config.load_dir = config.get_checkpoint_dir()\n",
    "\n",
    "meta, data_dir = load_metadata(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:25:35] </span>Auto image downscale factor of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>                                                 <a href=\"file:///home/ccl/.conda/envs/nerfstudio/lib/python3.8/site-packages/nerfstudio/data/dataparsers/nerfstudio_dataparser.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">nerfstudio_dataparser.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ccl/.conda/envs/nerfstudio/lib/python3.8/site-packages/nerfstudio/data/dataparsers/nerfstudio_dataparser.py#349\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">349</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[15:25:35]\u001b[0m\u001b[2;36m \u001b[0mAuto image downscale factor of \u001b[1;36m1\u001b[0m                                                 \u001b]8;id=461465;file:///home/ccl/.conda/envs/nerfstudio/lib/python3.8/site-packages/nerfstudio/data/dataparsers/nerfstudio_dataparser.py\u001b\\\u001b[2mnerfstudio_dataparser.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=351359;file:///home/ccl/.conda/envs/nerfstudio/lib/python3.8/site-packages/nerfstudio/data/dataparsers/nerfstudio_dataparser.py#349\u001b\\\u001b[2m349\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #808000; text-decoration-color: #808000\"> Dataset is overriding train_indices to </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">[</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">10</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">11</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">12</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">13</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">14</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">15</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">16</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">17</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">18</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">19</span><span style=\"color: #808000; text-decoration-color: #808000\">,</span> <a href=\"file:///home/ccl/.conda/envs/nerfstudio/lib/python3.8/site-packages/nerfstudio/data/dataparsers/nerfstudio_dataparser.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">nerfstudio_dataparser.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ccl/.conda/envs/nerfstudio/lib/python3.8/site-packages/nerfstudio/data/dataparsers/nerfstudio_dataparser.py#200\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">200</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">20</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">21</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">22</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">23</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">24</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">25</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">26</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">27</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">28</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">29</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">30</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">31</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">32</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">33</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">34</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">35</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">36</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">37</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">38</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">39</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">40</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">41</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">42</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">43</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">44</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">45</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">46</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">47</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">48</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">49</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">50</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">51</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">52</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">53</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">54</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">55</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">56</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">57</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">58</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">59</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">60</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">61</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">62</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">63</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">64</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">65</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">66</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">67</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">68</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">69</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">70</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">71</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">72</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">73</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">74</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">75</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">76</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">77</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">78</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">79</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                            </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">80</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">81</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">82</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">83</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">84</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">85</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">86</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">87</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">88</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">89</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">]</span>                                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                            </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[33m Dataset is overriding train_indices to \u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m10\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m11\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m12\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m13\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m14\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m15\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m16\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m17\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m18\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m19\u001b[0m\u001b[33m,\u001b[0m \u001b]8;id=355264;file:///home/ccl/.conda/envs/nerfstudio/lib/python3.8/site-packages/nerfstudio/data/dataparsers/nerfstudio_dataparser.py\u001b\\\u001b[2mnerfstudio_dataparser.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=460077;file:///home/ccl/.conda/envs/nerfstudio/lib/python3.8/site-packages/nerfstudio/data/dataparsers/nerfstudio_dataparser.py#200\u001b\\\u001b[2m200\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m\u001b[1;33m20\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m21\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m22\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m23\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m24\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m25\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m26\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m27\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m28\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m29\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m30\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m31\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m32\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m33\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m34\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m35\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m36\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m37\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m38\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m39\u001b[0m\u001b[33m, \u001b[0m \u001b[2m                            \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m\u001b[1;33m40\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m41\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m42\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m43\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m44\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m45\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m46\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m47\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m48\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m49\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m50\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m51\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m52\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m53\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m54\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m55\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m56\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m57\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m58\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m59\u001b[0m\u001b[33m, \u001b[0m \u001b[2m                            \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m\u001b[1;33m60\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m61\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m62\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m63\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m64\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m65\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m66\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m67\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m68\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m69\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m70\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m71\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m72\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m73\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m74\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m75\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m76\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m77\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m78\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m79\u001b[0m\u001b[33m, \u001b[0m \u001b[2m                            \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m\u001b[1;33m80\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m81\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m82\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m83\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m84\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m85\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m86\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m87\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m88\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m89\u001b[0m\u001b[1;33m]\u001b[0m                                          \u001b[2m                            \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #808000; text-decoration-color: #808000\"> Dataset is overriding val_indices to </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">[</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">90</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">91</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">92</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">93</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">94</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">95</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">96</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">97</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">98</span><span style=\"color: #808000; text-decoration-color: #808000\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">99</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">]</span>   <a href=\"file:///home/ccl/.conda/envs/nerfstudio/lib/python3.8/site-packages/nerfstudio/data/dataparsers/nerfstudio_dataparser.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">nerfstudio_dataparser.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ccl/.conda/envs/nerfstudio/lib/python3.8/site-packages/nerfstudio/data/dataparsers/nerfstudio_dataparser.py#200\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">200</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[33m Dataset is overriding val_indices to \u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m90\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m91\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m92\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m93\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m94\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m95\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m96\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m97\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m98\u001b[0m\u001b[33m, \u001b[0m\u001b[1;33m99\u001b[0m\u001b[1;33m]\u001b[0m   \u001b]8;id=297564;file:///home/ccl/.conda/envs/nerfstudio/lib/python3.8/site-packages/nerfstudio/data/dataparsers/nerfstudio_dataparser.py\u001b\\\u001b[2mnerfstudio_dataparser.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=537642;file:///home/ccl/.conda/envs/nerfstudio/lib/python3.8/site-packages/nerfstudio/data/dataparsers/nerfstudio_dataparser.py#200\u001b\\\u001b[2m200\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Setting up training dataset<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Setting up training dataset\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Caching all <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">80</span> images.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Caching all \u001b[1;36m80\u001b[0m images.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e61bf65d001941a684f417d3f0abd713",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Setting up evaluation dataset<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Setting up evaluation dataset\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Caching all <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> images.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Caching all \u001b[1;36m10\u001b[0m images.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e7f4714bcb34f53a438471231b2cd7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Loading latest checkpoint from load_dir\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Loading latest checkpoint from load_dir\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Done loading checkpoint from \n",
       "outputs/checkered_square_pyramid/nerfacto/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-15_152357/nerfstudio_models/step-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">000004000.</span>ckpt\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✅ Done loading checkpoint from \n",
       "outputs/checkered_square_pyramid/nerfacto/\u001b[1;36m2023\u001b[0m-\u001b[1;36m09\u001b[0m-15_152357/nerfstudio_models/step-\u001b[1;36m000004000.\u001b[0mckpt\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# setup pipeline (which includes the DataManager)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "pipeline = config.pipeline.setup(device=device, test_mode=\"val\")\n",
    "pipeline.eval()\n",
    "\n",
    "\n",
    "checkpoint_path, step = eval_load_checkpoint(config, pipeline)\n",
    "results_path = config.get_base_dir() / \"results.json\"\n",
    "render_output_path = config.get_base_dir() / \"renders\"\n",
    "render_output_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_60679/2119514443.py:17: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  return torch.unsqueeze(torch.from_numpy(depth), dim=-1).to(device=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.5547, device='cuda:0')\n",
      "tensor(4.4023, device='cuda:0')\n",
      "tensor(4.1914, device='cuda:0')\n",
      "tensor(4.1914, device='cuda:0')\n",
      "tensor(4.4023, device='cuda:0')\n",
      "tensor(4.5547, device='cuda:0')\n",
      "tensor(4.4023, device='cuda:0')\n",
      "tensor(4.1914, device='cuda:0')\n",
      "tensor(4.1914, device='cuda:0')\n",
      "tensor(4.4023, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import OpenEXR, Imath\n",
    "\n",
    "depth_filenames = pipeline.datamanager.eval_dataset.metadata[\"depth_filenames\"]\n",
    "\n",
    "def read_depth_map(file_path):\n",
    "    exr_file = OpenEXR.InputFile(file_path)\n",
    "    dw = exr_file.header()['dataWindow']\n",
    "    width = dw.max.x - dw.min.x + 1\n",
    "    height = dw.max.y - dw.min.y + 1\n",
    "    \n",
    "    pt = Imath.PixelType(Imath.PixelType.FLOAT)\n",
    "    depth_str = exr_file.channel('R', pt)\n",
    "    depth = np.frombuffer(depth_str, dtype=np.float32)\n",
    "    depth.shape = (height, width)  # reshape\n",
    "    \n",
    "    return torch.unsqueeze(torch.from_numpy(depth), dim=-1).to(device=device)\n",
    "\n",
    "for camera_ray_bundle, batch in pipeline.datamanager.fixed_indices_eval_dataloader:\n",
    "    image_idx = batch[\"image_idx\"]\n",
    "    depth_filepath = depth_filenames[image_idx]\n",
    "    depth = read_depth_map(str(depth_filepath))\n",
    "    mask = depth <= 1000\n",
    "    depth[depth > 1000] = 0\n",
    "    print(torch.max(depth[mask]))\n",
    "    outputs = pipeline.model.get_outputs_for_camera_ray_bundle(camera_ray_bundle)\n",
    "\n",
    "    rgb = outputs[\"rgb\"]\n",
    "    acc = colormaps.apply_colormap(outputs[\"accumulation\"])\n",
    "    depth_pred = colormaps.apply_depth_colormap(\n",
    "        outputs[\"depth\"],\n",
    "        accumulation=outputs[\"accumulation\"],\n",
    "    )\n",
    "    depth_gt = colormaps.apply_depth_colormap(\n",
    "        depth,\n",
    "    )\n",
    "    depth_gt = torch.concat([depth_gt, mask], dim=-1)\n",
    "\n",
    "    save_as_image(rgb, render_output_path / f\"rgb_pred_{image_idx:04d}.png\")\n",
    "    save_as_image(batch[\"image\"], render_output_path / f\"rgb_gt_{image_idx:04d}.png\")\n",
    "    save_as_image(acc, render_output_path / f\"acc_{image_idx:04d}.png\")\n",
    "    save_as_image(depth_pred, render_output_path / f\"depth_pred_{image_idx:04d}.png\")\n",
    "    save_as_image(depth_gt, render_output_path / f\"depth_gt_{image_idx:04d}.png\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "353"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# load data for coverting between original and normalized coodinate space\n",
    "dataparser_transforms_path = config.get_base_dir() / \"dataparser_transforms.json\"\n",
    "dataparser_transforms_data = json.load(open(dataparser_transforms_path))\n",
    "dataparser_scale = dataparser_transforms_data[\"scale\"]\n",
    "transform = torch.tensor(dataparser_transforms_data[\"transform\"])\n",
    "\n",
    "near_z = 0.15\n",
    "camera_ray_bundle = plane_eval_ray_bundle(dataparser_transforms_data, near_z).to(device)\n",
    "outputs = pipeline.model.get_outputs_for_camera_ray_bundle(camera_ray_bundle)\n",
    "\n",
    "rgb = outputs[\"rgb\"]\n",
    "acc = colormaps.apply_colormap(outputs[\"accumulation\"])\n",
    "depth = colormaps.apply_depth_colormap(\n",
    "    outputs[\"depth\"],\n",
    "    accumulation=outputs[\"accumulation\"],\n",
    ")\n",
    "\n",
    "z = near_z - (outputs[\"depth\"] / dataparser_scale)\n",
    "z_vis = colormaps.apply_depth_colormap(\n",
    "    torch.clamp(z, -0.3, 0.3),\n",
    "    accumulation=outputs[\"accumulation\"],\n",
    ")\n",
    "\n",
    "save_as_image(rgb, render_output_path / \"rgb.jpg\")\n",
    "save_as_image(acc, render_output_path / \"acc.jpg\")\n",
    "save_as_image(depth, render_output_path / \"depth.jpg\")\n",
    "save_as_image(z_vis, render_output_path / \"z.jpg\")\n",
    "torch.save(z_vis, render_output_path / \"z.pt\")\n",
    "\n",
    "# Get the output and define the names to save to\n",
    "benchmark_info = {\n",
    "    \"experiment_name\": config.experiment_name,\n",
    "    \"method_name\": config.method_name,\n",
    "    \"checkpoint\": str(checkpoint_path),\n",
    "    \"results\": {\n",
    "        \"max_z\": float(torch.max(z)),\n",
    "        \"min_z\": float(torch.min(z)),\n",
    "        \"std_z\": float(torch.std(z)),\n",
    "        \"mean_z\": float(torch.mean(z)),\n",
    "    },\n",
    "}\n",
    "# Save output to output file\n",
    "results_path.write_text(json.dumps(benchmark_info, indent=2), \"utf8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nerfstudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
